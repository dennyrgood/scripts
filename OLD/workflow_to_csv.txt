#!/usr/bin/env python3
"""
Workflow to CSV Converter
Extracts prompt data from ComfyUI workflow JSON and saves to CSV format.

Usage:
    python workflow_to_csv.py workflow.json
    python workflow_to_csv.py workflow.json -o output.csv
    python workflow_to_csv.py workflow.json --stats
"""

import json
import csv
import argparse
from collections import defaultdict
from typing import List, Dict


def extract_prompts_from_workflow(workflow_file: str, strict: bool = True, include_embedded: bool = True) -> List[Dict[str, str]]:
    """
    Extract prompt data from workflow JSON.
    
    Args:
        workflow_file: Path to the workflow JSON file
        strict: If True, only extract nodes with "LIB:" prefix (generated workflows)
                If False, extract all PrimitiveStringMultiline nodes
        include_embedded: If True, also search for embedded/grouped workflows
        
    Returns:
        List of prompt dictionaries with keys: category, title, prompt, node_id
    """
    # Load the workflow
    with open(workflow_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    all_prompts = []
    
    # Function to extract from a workflow structure
    def extract_from_workflow(workflow_data, source="main"):
        prompts = []
        skipped = 0
        
        # Get all PrimitiveStringMultiline nodes
        primitive_nodes = [n for n in workflow_data.get('nodes', []) if n.get('type') == 'PrimitiveStringMultiline']
        
        # Check if this looks like a generated prompt library workflow
        lib_nodes = [n for n in primitive_nodes if 'LIB:' in n.get('title', '')]
        
        if strict and len(lib_nodes) == 0 and len(primitive_nodes) > 0 and source == "main":
            # This doesn't look like a generated workflow
            print(f"\nNote: Main workflow doesn't appear to be a prompt library workflow.")
            print(f"Found {len(primitive_nodes)} PrimitiveStringMultiline node(s), but none with 'LIB:' prefix.")
            
            if include_embedded:
                print(f"Searching for embedded workflows...")
            else:
                print(f"\nUse --all flag to extract all prompt nodes regardless of naming convention.")
                return []
        
        nodes_to_process = lib_nodes if strict else primitive_nodes
        
        for node in nodes_to_process:
            title = node.get('title', '')
            
            if strict and 'LIB:' in title:
                # Parse the standard format: "LIB: CATEGORY - Prompt Title"
                title_clean = title.replace('LIB:', '').strip()
                
                # Split on first " - " to separate category and prompt title
                if ' - ' not in title_clean:
                    # No dash, use whole thing as title
                    category = "Uncategorized"
                    prompt_title = title_clean if title_clean else f"Node_{node.get('id', 'unknown')}"
                else:
                    parts = title_clean.split(' - ', 1)
                    category = parts[0].strip()
                    prompt_title = parts[1].strip()
            else:
                # Non-standard format - use node title as prompt title
                category = "Uncategorized"
                prompt_title = title if title else f"Node_{node.get('id', 'unknown')}"
            
            # Get the prompt text from widgets_values
            if not node.get('widgets_values') or len(node['widgets_values']) == 0:
                skipped += 1
                continue
            
            prompt_text = node['widgets_values'][0]
            
            # Validate that we have prompt text
            if not prompt_text or not prompt_text.strip():
                skipped += 1
                continue
            
            # Add to results
            prompts.append({
                'category': category,
                'title': prompt_title,
                'prompt': prompt_text,
                'node_id': node.get('id', 'unknown'),
                'source': source,
                'position': tuple(node.get('pos', [0, 0]))
            })
        
        return prompts
    
    # Extract from main workflow
    main_prompts = extract_from_workflow(data, "main")
    all_prompts.extend(main_prompts)
    
    # Search for embedded workflows if requested
    if include_embedded:
        # Check for embedded workflows in definitions.subgraphs
        if 'definitions' in data and 'subgraphs' in data['definitions']:
            subgraphs = data['definitions']['subgraphs']
            
            for idx, subgraph in enumerate(subgraphs):
                if isinstance(subgraph, dict) and 'nodes' in subgraph:
                    embedded_prompts = extract_from_workflow(subgraph, f"embedded_{idx}")
                    if embedded_prompts:
                        print(f"Found {len(embedded_prompts)} prompts in embedded workflow #{idx}")
                        all_prompts.extend(embedded_prompts)
    
    if not all_prompts and not strict:
        print("No prompts found in any workflow (main or embedded).")
    
    return all_prompts


def save_to_csv(prompts: List[Dict[str, str]], output_file: str, 
                include_node_ids: bool = False) -> None:
    """
    Save prompts to CSV file.
    
    Args:
        prompts: List of prompt dictionaries
        output_file: Path to output CSV file
        include_node_ids: Whether to include node ID column
    """
    # Sort prompts by category, then by title
    prompts_sorted = sorted(prompts, key=lambda x: (x['category'], x['title']))
    
    with open(output_file, 'w', newline='', encoding='utf-8') as f:
        # Determine columns
        if include_node_ids:
            fieldnames = ['Category', 'Modifier name', 'Prompt text', 'Node ID']
        else:
            fieldnames = ['Category', 'Modifier name', 'Prompt text']
        
        writer = csv.writer(f)
        
        # Write header
        writer.writerow(fieldnames)
        
        # Write data
        for p in prompts_sorted:
            row = [p['category'], p['title'], p['prompt']]
            if include_node_ids:
                row.append(p['node_id'])
            writer.writerow(row)


def print_statistics(prompts: List[Dict[str, str]]) -> None:
    """Print statistics about the extracted prompts."""
    if not prompts:
        print("No prompts found!")
        return
    
    print("\n" + "="*60)
    print("EXTRACTION STATISTICS")
    print("="*60)
    
    # Total count
    print(f"\nTotal prompts extracted: {len(prompts)}")
    
    # Count by category
    category_counts = defaultdict(int)
    for p in prompts:
        category_counts[p['category']] += 1
    
    print(f"\nCategories found: {len(category_counts)}")
    print("\nPrompts per category:")
    for category in sorted(category_counts.keys()):
        count = category_counts[category]
        print(f"  {category:.<40} {count:>3}")
    
    # Longest/shortest prompts
    prompt_lengths = [(p['title'], len(p['prompt'])) for p in prompts]
    prompt_lengths.sort(key=lambda x: x[1])
    
    print(f"\nPrompt text length range:")
    print(f"  Shortest: {prompt_lengths[0][1]} chars - '{prompt_lengths[0][0]}'")
    print(f"  Longest:  {prompt_lengths[-1][1]} chars - '{prompt_lengths[-1][0]}'")
    print(f"  Average:  {sum(l for _, l in prompt_lengths) // len(prompt_lengths)} chars")
    
    # Check for duplicates
    titles = [p['title'] for p in prompts]
    duplicates = len(titles) - len(set(titles))
    if duplicates > 0:
        print(f"\n⚠ Warning: Found {duplicates} duplicate prompt titles")
    else:
        print(f"\n✓ No duplicate titles found")
    
    print("="*60 + "\n")


def main():
    parser = argparse.ArgumentParser(
        description='Extract prompts from ComfyUI workflow JSON to CSV',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python workflow_to_csv.py workflow.json
  python workflow_to_csv.py workflow.json -o my_prompts.csv
  python workflow_to_csv.py workflow.json --stats
  python workflow_to_csv.py workflow.json --include-ids
  python workflow_to_csv.py regular_workflow.json --all  # Extract from non-library workflows
  
Note:
  By default, this script only extracts from prompt library workflows
  (generated by workflow_generator.py with "LIB:" prefix in titles).
  
  Use --all to extract from regular ComfyUI workflows.
        """
    )
    
    parser.add_argument('workflow', 
                       help='Input workflow JSON file')
    parser.add_argument('-o', '--output', 
                       default='extracted_prompts.csv',
                       help='Output CSV file (default: extracted_prompts.csv)')
    parser.add_argument('--stats', 
                       action='store_true',
                       help='Show detailed statistics')
    parser.add_argument('--include-ids', 
                       action='store_true',
                       help='Include node IDs in CSV output')
    parser.add_argument('--all',
                       action='store_true',
                       help='Extract all PrimitiveStringMultiline nodes (not just LIB: prefixed)')
    parser.add_argument('--quiet', 
                       action='store_true',
                       help='Suppress all output except errors')
    
    args = parser.parse_args()
    
    try:
        # Extract prompts
        if not args.quiet:
            print(f"Reading workflow from: {args.workflow}")
        
        prompts = extract_prompts_from_workflow(args.workflow, strict=not args.all)
        
        if not prompts:
            if not args.quiet:
                print("\n" + "="*60)
                print("WORKFLOW DIAGNOSIS")
                print("="*60)
                
                # Load workflow to provide helpful info
                with open(args.workflow, 'r') as f:
                    data = json.load(f)
                
                total_nodes = len(data.get('nodes', []))
                primitive_nodes = [n for n in data['nodes'] if n.get('type') == 'PrimitiveStringMultiline']
                
                print(f"\nTotal nodes in workflow: {total_nodes}")
                print(f"PrimitiveStringMultiline nodes: {len(primitive_nodes)}")
                
                if primitive_nodes:
                    print("\nFound these prompt nodes:")
                    for node in primitive_nodes[:5]:
                        title = node.get('title', 'NO TITLE')
                        prompt = node.get('widgets_values', [''])[0][:60] if node.get('widgets_values') else ''
                        print(f"  - {title}")
                        print(f"    {prompt}...")
                    
                    print("\nThis appears to be a regular ComfyUI workflow, not a prompt library.")
                    print("To extract prompts anyway, use: --all flag")
                    print(f"\nExample: python workflow_to_csv.py {args.workflow} --all")
                else:
                    print("\nNo PrimitiveStringMultiline nodes found.")
                    print("This workflow doesn't contain extractable prompts.")
                
                print("="*60)
            
            return 1
        
        # Show statistics if requested
        if args.stats and not args.quiet:
            print_statistics(prompts)
        
        # Save to CSV
        save_to_csv(prompts, args.output, args.include_ids)
        
        if not args.quiet:
            print(f"✓ Extracted {len(prompts)} prompts")
            print(f"✓ Categories: {len(set(p['category'] for p in prompts))}")
            print(f"✓ Saved to: {args.output}")
        
        return 0
        
    except FileNotFoundError:
        print(f"Error: File not found: {args.workflow}")
        return 1
    except json.JSONDecodeError:
        print(f"Error: Invalid JSON in file: {args.workflow}")
        return 1
    except Exception as e:
        print(f"Error: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    exit(main())
